{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_LSTM.ipynb","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%203%20-%20Lesson%202.ipynb","timestamp":1582544059352},{"file_id":"1OOzqEhzmkFQOtmEGwMhiLxB_D2osx4eM","timestamp":1556803950670}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jGwXGIXvFhXW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"outputId":"c967e641-dc08-4566-f59e-2d41ca4df9c7"},"source":["import json\n","import tensorflow as tf\n","import numpy as np\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n","    -O /tmp/sarcasm.json\n","\n","vocab_size = 1000\n","embedding_dim = 16\n","max_length = 120\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"<OOV>\"\n","training_size = 20000\n","\n","\n","with open(\"/tmp/sarcasm.json\", 'r') as f:\n","    datastore = json.load(f)\n","\n","\n","sentences = []\n","labels = []\n","urls = []\n","for item in datastore:\n","    sentences.append(item['headline'])\n","    labels.append(item['is_sarcastic'])\n","\n","training_sentences = sentences[0:training_size]\n","testing_sentences = sentences[training_size:]\n","training_labels = labels[0:training_size]\n","testing_labels = labels[training_size:]\n","\n","tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n","tokenizer.fit_on_texts(training_sentences)\n","\n","word_index = tokenizer.word_index\n","\n","training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n","    tf.keras.layers.Dense(24, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.summary()\n","\n","num_epochs = 50\n","training_padded = np.array(training_padded)\n","training_labels = np.array(training_labels)\n","testing_padded = np.array(testing_padded)\n","testing_labels = np.array(testing_labels)\n","history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-02-24 11:38:42--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 2607:f8b0:4001:c05::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5643545 (5.4M) [application/json]\n","Saving to: ‘/tmp/sarcasm.json’\n","\n","\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.04s   \n","\n","2020-02-24 11:38:42 (126 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 120, 16)           16000     \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 64)                12544     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 24)                1560      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 25        \n","=================================================================\n","Total params: 30,129\n","Trainable params: 30,129\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 6709 samples\n","Epoch 1/50\n","20000/20000 [==============================] - 268s 13ms/sample - loss: 0.4507 - acc: 0.7718 - val_loss: 0.3913 - val_acc: 0.8186\n","Epoch 2/50\n","17472/20000 [=========================>....] - ETA: 31s - loss: 0.3597 - acc: 0.8369"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g9DC6dmLF8DC","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","\n","plot_graphs(history, 'acc')\n","plot_graphs(history, 'loss')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZEZIUppGhdi","colab_type":"code","colab":{}},"source":["model.save(\"test.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQhexVJx_WDZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}