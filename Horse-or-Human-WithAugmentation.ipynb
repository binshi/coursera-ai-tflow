{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Horse-or-Human-WithAugmentation.ipynb","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%204%20-%20Notebook.ipynb","timestamp":1581917163802}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"RXZT2UsyIVe_","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"eab4a9b8-bcb2-494a-c081-fa524e04f65b","executionInfo":{"status":"ok","timestamp":1581917199361,"user_tz":-330,"elapsed":7714,"user":{"displayName":"SHIBIN PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDKQidi2gUH5NG7-2ySWFqsGpFP9a-nGfZGPcw7Eg=s64","userId":"04796874744630433056"}}},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n","    -O /tmp/horse-or-human.zip\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n","    -O /tmp/validation-horse-or-human.zip\n","  \n","import os\n","import zipfile\n","\n","local_zip = '/tmp/horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/horse-or-human')\n","local_zip = '/tmp/validation-horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/validation-horse-or-human')\n","zip_ref.close()\n","# Directory with our training horse pictures\n","train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","train_human_dir = os.path.join('/tmp/horse-or-human/humans')\n","\n","# Directory with our training horse pictures\n","validation_horse_dir = os.path.join('/tmp/validation-horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","validation_human_dir = os.path.join('/tmp/validation-horse-or-human/humans')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-02-17 05:26:33--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c09::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 149574867 (143M) [application/zip]\n","Saving to: ‘/tmp/horse-or-human.zip’\n","\n","/tmp/horse-or-human 100%[===================>] 142.65M   145MB/s    in 1.0s    \n","\n","2020-02-17 05:26:34 (145 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n","\n","--2020-02-17 05:26:35--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 2607:f8b0:400e:c08::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11480187 (11M) [application/zip]\n","Saving to: ‘/tmp/validation-horse-or-human.zip’\n","\n","/tmp/validation-hor 100%[===================>]  10.95M  61.3MB/s    in 0.2s    \n","\n","2020-02-17 05:26:36 (61.3 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5oqBkNBJmtUv"},"source":["## Building a Small Model from Scratch\n","\n","But before we continue, let's start defining the model:\n","\n","Step 1 will be to import tensorflow."]},{"cell_type":"code","metadata":{"id":"qvfZg3LQbD-5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":63},"outputId":"fc5ab5d8-da48-4ce2-ca5e-9799015d5550","executionInfo":{"status":"ok","timestamp":1581917200985,"user_tz":-330,"elapsed":9332,"user":{"displayName":"SHIBIN PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDKQidi2gUH5NG7-2ySWFqsGpFP9a-nGfZGPcw7Eg=s64","userId":"04796874744630433056"}}},"source":["import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BnhYCP4tdqjC"},"source":["We then add convolutional layers as in the previous example, and flatten the final result to feed into the densely connected layers."]},{"cell_type":"markdown","metadata":{"id":"gokG5HKpdtzm","colab_type":"text"},"source":["Finally we add the densely connected layers. \n","\n","Note that because we are facing a two-class classification problem, i.e. a *binary classification problem*, we will end our network with a [*sigmoid* activation](https://wikipedia.org/wiki/Sigmoid_function), so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0)."]},{"cell_type":"code","metadata":{"id":"PixZ2s5QbYQ3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"49cb39b7-8a6e-4b03-d2fc-c83af0bbe8e3","executionInfo":{"status":"ok","timestamp":1581917200986,"user_tz":-330,"elapsed":9330,"user":{"displayName":"SHIBIN PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDKQidi2gUH5NG7-2ySWFqsGpFP9a-nGfZGPcw7Eg=s64","userId":"04796874744630433056"}}},"source":["model = tf.keras.models.Sequential([\n","    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The third convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fifth convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    # 512 neuron hidden layer\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8DHWhFP_uhq3","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"d38e1b66-2ab6-4b98-e421-5a8d45b73dfe","executionInfo":{"status":"ok","timestamp":1581917200987,"user_tz":-330,"elapsed":7358,"user":{"displayName":"SHIBIN PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDKQidi2gUH5NG7-2ySWFqsGpFP9a-nGfZGPcw7Eg=s64","userId":"04796874744630433056"}}},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(lr=1e-4),\n","              metrics=['acc'])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ClebU9NJg99G","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ece91919-e9d2-4ea8-de96-b2b4f4646c73","executionInfo":{"status":"ok","timestamp":1581917201330,"user_tz":-330,"elapsed":7369,"user":{"displayName":"SHIBIN PAUL","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDKQidi2gUH5NG7-2ySWFqsGpFP9a-nGfZGPcw7Eg=s64","userId":"04796874744630433056"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale=1/255)\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        '/tmp/horse-or-human/',  # This is the source directory for training images\n","        target_size=(300, 300),  # All images will be resized to 150x150\n","        batch_size=128,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","validation_generator = validation_datagen.flow_from_directory(\n","        '/tmp/validation-horse-or-human/',  # This is the source directory for training images\n","        target_size=(300, 300),  # All images will be resized to 150x150\n","        batch_size=32,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 1027 images belonging to 2 classes.\n","Found 256 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fb1_lgobv81m","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0337ead6-ac0f-4f5e-dca1-18f55d7ec167"},"source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=8,  \n","      epochs=100,\n","      verbose=1,\n","      validation_data = validation_generator,\n","      validation_steps=8)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","7/8 [=========================>....] - ETA: 1s - loss: 0.6882 - acc: 0.5370Epoch 1/100\n","8/8 [==============================] - 1s 183ms/step - loss: 0.6797 - acc: 0.8281\n","8/8 [==============================] - 18s 2s/step - loss: 0.6902 - acc: 0.5195 - val_loss: 0.6797 - val_acc: 0.8281\n","Epoch 2/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6821 - acc: 0.5798Epoch 1/100\n","8/8 [==============================] - 1s 157ms/step - loss: 0.6695 - acc: 0.5273\n","8/8 [==============================] - 21s 3s/step - loss: 0.6815 - acc: 0.5729 - val_loss: 0.6695 - val_acc: 0.5273\n","Epoch 3/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6672 - acc: 0.6529Epoch 1/100\n","8/8 [==============================] - 1s 157ms/step - loss: 0.6278 - acc: 0.5000\n","8/8 [==============================] - 24s 3s/step - loss: 0.6661 - acc: 0.6582 - val_loss: 0.6278 - val_acc: 0.5000\n","Epoch 4/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6791 - acc: 0.6524Epoch 1/100\n","8/8 [==============================] - 1s 158ms/step - loss: 0.6080 - acc: 0.6797\n","8/8 [==============================] - 21s 3s/step - loss: 0.6732 - acc: 0.6574 - val_loss: 0.6080 - val_acc: 0.6797\n","Epoch 5/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6755 - acc: 0.6524Epoch 1/100\n","8/8 [==============================] - 1s 156ms/step - loss: 0.6003 - acc: 0.6719\n","8/8 [==============================] - 21s 3s/step - loss: 0.6680 - acc: 0.6696 - val_loss: 0.6003 - val_acc: 0.6719\n","Epoch 6/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6248 - acc: 0.7341Epoch 1/100\n","8/8 [==============================] - 1s 154ms/step - loss: 0.5328 - acc: 0.7852\n","8/8 [==============================] - 21s 3s/step - loss: 0.6241 - acc: 0.7375 - val_loss: 0.5328 - val_acc: 0.7852\n","Epoch 7/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6281 - acc: 0.7211Epoch 1/100\n","8/8 [==============================] - 1s 158ms/step - loss: 0.5437 - acc: 0.7031\n","8/8 [==============================] - 21s 3s/step - loss: 0.6224 - acc: 0.7164 - val_loss: 0.5437 - val_acc: 0.7031\n","Epoch 8/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.6051 - acc: 0.7134Epoch 1/100\n","8/8 [==============================] - 1s 162ms/step - loss: 0.5665 - acc: 0.6562\n","8/8 [==============================] - 21s 3s/step - loss: 0.5995 - acc: 0.7219 - val_loss: 0.5665 - val_acc: 0.6562\n","Epoch 9/100\n","6/8 [=====================>........] - ETA: 5s - loss: 0.5622 - acc: 0.7500Epoch 1/100\n","8/8 [==============================] - 1s 163ms/step - loss: 0.7178 - acc: 0.5547\n","8/8 [==============================] - 21s 3s/step - loss: 0.5469 - acc: 0.7386 - val_loss: 0.7178 - val_acc: 0.5547\n","Epoch 10/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5549 - acc: 0.7056Epoch 1/100\n","8/8 [==============================] - 1s 165ms/step - loss: 0.5986 - acc: 0.6289\n","8/8 [==============================] - 21s 3s/step - loss: 0.5568 - acc: 0.7063 - val_loss: 0.5986 - val_acc: 0.6289\n","Epoch 11/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4797 - acc: 0.7704Epoch 1/100\n","8/8 [==============================] - 1s 182ms/step - loss: 0.5675 - acc: 0.6836\n","8/8 [==============================] - 21s 3s/step - loss: 0.4848 - acc: 0.7731 - val_loss: 0.5675 - val_acc: 0.6836\n","Epoch 12/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5225 - acc: 0.7549Epoch 1/100\n","8/8 [==============================] - 1s 163ms/step - loss: 0.9923 - acc: 0.5352\n","8/8 [==============================] - 21s 3s/step - loss: 0.5221 - acc: 0.7508 - val_loss: 0.9923 - val_acc: 0.5352\n","Epoch 13/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4921 - acc: 0.7768Epoch 1/100\n","8/8 [==============================] - 1s 164ms/step - loss: 0.7071 - acc: 0.6562\n","8/8 [==============================] - 24s 3s/step - loss: 0.4870 - acc: 0.7764 - val_loss: 0.7071 - val_acc: 0.6562\n","Epoch 14/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4521 - acc: 0.7756Epoch 1/100\n","8/8 [==============================] - 1s 168ms/step - loss: 1.0624 - acc: 0.5586\n","8/8 [==============================] - 21s 3s/step - loss: 0.4596 - acc: 0.7775 - val_loss: 1.0624 - val_acc: 0.5586\n","Epoch 15/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4598 - acc: 0.7873Epoch 1/100\n","8/8 [==============================] - 1s 164ms/step - loss: 0.7040 - acc: 0.6562\n","8/8 [==============================] - 18s 2s/step - loss: 0.4730 - acc: 0.7868 - val_loss: 0.7040 - val_acc: 0.6562\n","Epoch 16/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4551 - acc: 0.7857Epoch 1/100\n","8/8 [==============================] - 1s 164ms/step - loss: 1.2115 - acc: 0.5547\n","8/8 [==============================] - 24s 3s/step - loss: 0.4540 - acc: 0.7900 - val_loss: 1.2115 - val_acc: 0.5547\n","Epoch 17/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5328 - acc: 0.7536Epoch 1/100\n","8/8 [==============================] - 1s 160ms/step - loss: 0.8753 - acc: 0.6133\n","8/8 [==============================] - 21s 3s/step - loss: 0.5189 - acc: 0.7608 - val_loss: 0.8753 - val_acc: 0.6133\n","Epoch 18/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5113 - acc: 0.7484Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 0.9039 - acc: 0.5938\n","8/8 [==============================] - 21s 3s/step - loss: 0.4976 - acc: 0.7586 - val_loss: 0.9039 - val_acc: 0.5938\n","Epoch 19/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4273 - acc: 0.8158Epoch 1/100\n","8/8 [==============================] - 1s 165ms/step - loss: 1.0339 - acc: 0.5938\n","8/8 [==============================] - 21s 3s/step - loss: 0.4304 - acc: 0.8109 - val_loss: 1.0339 - val_acc: 0.5938\n","Epoch 20/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5109 - acc: 0.7471Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 0.8053 - acc: 0.6445\n","8/8 [==============================] - 21s 3s/step - loss: 0.4966 - acc: 0.7564 - val_loss: 0.8053 - val_acc: 0.6445\n","Epoch 21/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5455 - acc: 0.7497Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 0.9522 - acc: 0.6133\n","8/8 [==============================] - 21s 3s/step - loss: 0.5200 - acc: 0.7697 - val_loss: 0.9522 - val_acc: 0.6133\n","Epoch 22/100\n","6/8 [=====================>........] - ETA: 5s - loss: 0.3968 - acc: 0.8307Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 1.4494 - acc: 0.5547\n","8/8 [==============================] - 21s 3s/step - loss: 0.4165 - acc: 0.8254 - val_loss: 1.4494 - val_acc: 0.5547\n","Epoch 23/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4016 - acc: 0.8106Epoch 1/100\n","8/8 [==============================] - 1s 160ms/step - loss: 1.6083 - acc: 0.5469\n","8/8 [==============================] - 21s 3s/step - loss: 0.4148 - acc: 0.8020 - val_loss: 1.6083 - val_acc: 0.5469\n","Epoch 24/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3870 - acc: 0.8270Epoch 1/100\n","8/8 [==============================] - 1s 165ms/step - loss: 0.9720 - acc: 0.6367\n","8/8 [==============================] - 24s 3s/step - loss: 0.3865 - acc: 0.8271 - val_loss: 0.9720 - val_acc: 0.6367\n","Epoch 25/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3874 - acc: 0.8197Epoch 1/100\n","8/8 [==============================] - 1s 185ms/step - loss: 1.3913 - acc: 0.5742\n","8/8 [==============================] - 21s 3s/step - loss: 0.3771 - acc: 0.8343 - val_loss: 1.3913 - val_acc: 0.5742\n","Epoch 26/100\n","6/8 [=====================>........] - ETA: 5s - loss: 0.3928 - acc: 0.8242Epoch 1/100\n","8/8 [==============================] - 1s 159ms/step - loss: 1.4632 - acc: 0.5625\n","8/8 [==============================] - 21s 3s/step - loss: 0.4455 - acc: 0.8131 - val_loss: 1.4632 - val_acc: 0.5625\n","Epoch 27/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3504 - acc: 0.8067Epoch 1/100\n","8/8 [==============================] - 1s 165ms/step - loss: 1.1396 - acc: 0.6055\n","8/8 [==============================] - 21s 3s/step - loss: 0.3651 - acc: 0.8098 - val_loss: 1.1396 - val_acc: 0.6055\n","Epoch 28/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5037 - acc: 0.7834Epoch 1/100\n","8/8 [==============================] - 1s 169ms/step - loss: 1.2000 - acc: 0.5898\n","8/8 [==============================] - 21s 3s/step - loss: 0.4928 - acc: 0.7864 - val_loss: 1.2000 - val_acc: 0.5898\n","Epoch 29/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3524 - acc: 0.8171Epoch 1/100\n","8/8 [==============================] - 1s 160ms/step - loss: 1.2271 - acc: 0.5977\n","8/8 [==============================] - 20s 3s/step - loss: 0.3559 - acc: 0.8187 - val_loss: 1.2271 - val_acc: 0.5977\n","Epoch 30/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4861 - acc: 0.7886Epoch 1/100\n","8/8 [==============================] - 1s 173ms/step - loss: 1.1618 - acc: 0.5938\n","8/8 [==============================] - 21s 3s/step - loss: 0.4639 - acc: 0.7987 - val_loss: 1.1618 - val_acc: 0.5938\n","Epoch 31/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3425 - acc: 0.8534Epoch 1/100\n","8/8 [==============================] - 1s 163ms/step - loss: 1.3875 - acc: 0.5859\n","8/8 [==============================] - 21s 3s/step - loss: 0.3381 - acc: 0.8587 - val_loss: 1.3875 - val_acc: 0.5859\n","Epoch 32/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3620 - acc: 0.8326Epoch 1/100\n","8/8 [==============================] - 1s 162ms/step - loss: 1.6617 - acc: 0.5664\n","8/8 [==============================] - 24s 3s/step - loss: 0.3515 - acc: 0.8418 - val_loss: 1.6617 - val_acc: 0.5664\n","Epoch 33/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4049 - acc: 0.8223Epoch 1/100\n","8/8 [==============================] - 1s 170ms/step - loss: 2.0433 - acc: 0.5156\n","8/8 [==============================] - 18s 2s/step - loss: 0.3988 - acc: 0.8217 - val_loss: 2.0433 - val_acc: 0.5156\n","Epoch 34/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3160 - acc: 0.8547Epoch 1/100\n","8/8 [==============================] - 1s 169ms/step - loss: 1.5668 - acc: 0.5938\n","8/8 [==============================] - 21s 3s/step - loss: 0.3193 - acc: 0.8532 - val_loss: 1.5668 - val_acc: 0.5938\n","Epoch 35/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3076 - acc: 0.8795Epoch 1/100\n","8/8 [==============================] - 1s 165ms/step - loss: 1.2552 - acc: 0.6289\n","8/8 [==============================] - 24s 3s/step - loss: 0.3169 - acc: 0.8721 - val_loss: 1.2552 - val_acc: 0.6289\n","Epoch 36/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3720 - acc: 0.8314Epoch 1/100\n","8/8 [==============================] - 1s 177ms/step - loss: 1.5375 - acc: 0.5898\n","8/8 [==============================] - 21s 3s/step - loss: 0.3683 - acc: 0.8365 - val_loss: 1.5375 - val_acc: 0.5898\n","Epoch 37/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3884 - acc: 0.8327Epoch 1/100\n","8/8 [==============================] - 1s 163ms/step - loss: 1.6515 - acc: 0.5859\n","8/8 [==============================] - 22s 3s/step - loss: 0.3813 - acc: 0.8420 - val_loss: 1.6515 - val_acc: 0.5859\n","Epoch 38/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3481 - acc: 0.8444Epoch 1/100\n","8/8 [==============================] - 1s 167ms/step - loss: 1.4570 - acc: 0.6016\n","8/8 [==============================] - 21s 3s/step - loss: 0.3610 - acc: 0.8287 - val_loss: 1.4570 - val_acc: 0.6016\n","Epoch 39/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3097 - acc: 0.8661Epoch 1/100\n","8/8 [==============================] - 1s 179ms/step - loss: 1.8020 - acc: 0.5781\n","8/8 [==============================] - 24s 3s/step - loss: 0.3055 - acc: 0.8701 - val_loss: 1.8020 - val_acc: 0.5781\n","Epoch 40/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2840 - acc: 0.8677Epoch 1/100\n","8/8 [==============================] - 1s 167ms/step - loss: 0.7268 - acc: 0.7383\n","8/8 [==============================] - 18s 2s/step - loss: 0.2870 - acc: 0.8669 - val_loss: 0.7268 - val_acc: 0.7383\n","Epoch 41/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3304 - acc: 0.8392Epoch 1/100\n","8/8 [==============================] - 1s 169ms/step - loss: 1.3829 - acc: 0.6172\n","8/8 [==============================] - 21s 3s/step - loss: 0.3165 - acc: 0.8576 - val_loss: 1.3829 - val_acc: 0.6172\n","Epoch 42/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2942 - acc: 0.8828Epoch 1/100\n","8/8 [==============================] - 1s 169ms/step - loss: 2.0857 - acc: 0.5586\n","8/8 [==============================] - 24s 3s/step - loss: 0.2890 - acc: 0.8838 - val_loss: 2.0857 - val_acc: 0.5586\n","Epoch 43/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.5160 - acc: 0.8353Epoch 1/100\n","8/8 [==============================] - 1s 160ms/step - loss: 1.8118 - acc: 0.5820\n","8/8 [==============================] - 21s 3s/step - loss: 0.4742 - acc: 0.8409 - val_loss: 1.8118 - val_acc: 0.5820\n","Epoch 44/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2509 - acc: 0.8872Epoch 1/100\n","8/8 [==============================] - 1s 166ms/step - loss: 1.2571 - acc: 0.6523\n","8/8 [==============================] - 21s 3s/step - loss: 0.2550 - acc: 0.8854 - val_loss: 1.2571 - val_acc: 0.6523\n","Epoch 45/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3450 - acc: 0.8249Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 1.9621 - acc: 0.5781\n","8/8 [==============================] - 22s 3s/step - loss: 0.3388 - acc: 0.8387 - val_loss: 1.9621 - val_acc: 0.5781\n","Epoch 46/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2549 - acc: 0.8794Epoch 1/100\n","8/8 [==============================] - 1s 166ms/step - loss: 1.3339 - acc: 0.6328\n","8/8 [==============================] - 21s 3s/step - loss: 0.2718 - acc: 0.8765 - val_loss: 1.3339 - val_acc: 0.6328\n","Epoch 47/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2878 - acc: 0.9014Epoch 1/100\n","8/8 [==============================] - 1s 162ms/step - loss: 2.0130 - acc: 0.5742\n","8/8 [==============================] - 21s 3s/step - loss: 0.2884 - acc: 0.8966 - val_loss: 2.0130 - val_acc: 0.5742\n","Epoch 48/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3006 - acc: 0.8781Epoch 1/100\n","8/8 [==============================] - 1s 162ms/step - loss: 1.8908 - acc: 0.5742\n","8/8 [==============================] - 22s 3s/step - loss: 0.2969 - acc: 0.8810 - val_loss: 1.8908 - val_acc: 0.5742\n","Epoch 49/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2666 - acc: 0.8690Epoch 1/100\n","8/8 [==============================] - 1s 168ms/step - loss: 2.0107 - acc: 0.5742\n","8/8 [==============================] - 21s 3s/step - loss: 0.2707 - acc: 0.8710 - val_loss: 2.0107 - val_acc: 0.5742\n","Epoch 50/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2866 - acc: 0.8772Epoch 1/100\n","8/8 [==============================] - 1s 174ms/step - loss: 1.8300 - acc: 0.5859\n","8/8 [==============================] - 24s 3s/step - loss: 0.2818 - acc: 0.8789 - val_loss: 1.8300 - val_acc: 0.5859\n","Epoch 51/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3913 - acc: 0.8495Epoch 1/100\n","8/8 [==============================] - 1s 165ms/step - loss: 1.7856 - acc: 0.5898\n","8/8 [==============================] - 21s 3s/step - loss: 0.3676 - acc: 0.8598 - val_loss: 1.7856 - val_acc: 0.5898\n","Epoch 52/100\n","6/8 [=====================>........] - ETA: 4s - loss: 0.2481 - acc: 0.8725Epoch 1/100\n","8/8 [==============================] - 1s 159ms/step - loss: 1.8543 - acc: 0.6016\n","8/8 [==============================] - 18s 2s/step - loss: 0.2363 - acc: 0.8773 - val_loss: 1.8543 - val_acc: 0.6016\n","Epoch 53/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2255 - acc: 0.9118Epoch 1/100\n","8/8 [==============================] - 1s 175ms/step - loss: 1.7502 - acc: 0.6250\n","8/8 [==============================] - 24s 3s/step - loss: 0.2290 - acc: 0.9082 - val_loss: 1.7502 - val_acc: 0.6250\n","Epoch 54/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3039 - acc: 0.8794Epoch 1/100\n","8/8 [==============================] - 1s 164ms/step - loss: 1.8189 - acc: 0.6016\n","8/8 [==============================] - 21s 3s/step - loss: 0.2890 - acc: 0.8854 - val_loss: 1.8189 - val_acc: 0.6016\n","Epoch 55/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.4546 - acc: 0.8418Epoch 1/100\n","8/8 [==============================] - 1s 162ms/step - loss: 1.7056 - acc: 0.5742\n","8/8 [==============================] - 21s 3s/step - loss: 0.4189 - acc: 0.8543 - val_loss: 1.7056 - val_acc: 0.5742\n","Epoch 56/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3065 - acc: 0.8820Epoch 1/100\n","8/8 [==============================] - 1s 167ms/step - loss: 2.0240 - acc: 0.5664\n","8/8 [==============================] - 22s 3s/step - loss: 0.2946 - acc: 0.8865 - val_loss: 2.0240 - val_acc: 0.5664\n","Epoch 57/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2513 - acc: 0.8929Epoch 1/100\n","8/8 [==============================] - 1s 166ms/step - loss: 1.9814 - acc: 0.5703\n","8/8 [==============================] - 24s 3s/step - loss: 0.2459 - acc: 0.8984 - val_loss: 1.9814 - val_acc: 0.5703\n","Epoch 58/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2317 - acc: 0.9056Epoch 1/100\n","8/8 [==============================] - 1s 167ms/step - loss: 2.5724 - acc: 0.5586\n","8/8 [==============================] - 18s 2s/step - loss: 0.2379 - acc: 0.9018 - val_loss: 2.5724 - val_acc: 0.5586\n","Epoch 59/100\n","6/8 [=====================>........] - ETA: 5s - loss: 0.2204 - acc: 0.9115Epoch 1/100\n","8/8 [==============================] - 1s 168ms/step - loss: 3.1352 - acc: 0.5352\n","8/8 [==============================] - 22s 3s/step - loss: 0.2065 - acc: 0.9077 - val_loss: 3.1352 - val_acc: 0.5352\n","Epoch 60/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2587 - acc: 0.8873Epoch 1/100\n","8/8 [==============================] - 1s 164ms/step - loss: 1.2668 - acc: 0.6641\n","8/8 [==============================] - 24s 3s/step - loss: 0.2623 - acc: 0.8809 - val_loss: 1.2668 - val_acc: 0.6641\n","Epoch 61/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2260 - acc: 0.9040Epoch 1/100\n","8/8 [==============================] - 1s 169ms/step - loss: 1.4773 - acc: 0.6484\n","8/8 [==============================] - 21s 3s/step - loss: 0.2334 - acc: 0.8999 - val_loss: 1.4773 - val_acc: 0.6484\n","Epoch 62/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1904 - acc: 0.9157Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 1.6395 - acc: 0.6523\n","8/8 [==============================] - 18s 2s/step - loss: 0.1745 - acc: 0.9160 - val_loss: 1.6395 - val_acc: 0.6523\n","Epoch 63/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2849 - acc: 0.8739Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 2.0885 - acc: 0.5977\n","8/8 [==============================] - 24s 3s/step - loss: 0.2630 - acc: 0.8867 - val_loss: 2.0885 - val_acc: 0.5977\n","Epoch 64/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2122 - acc: 0.8936Epoch 1/100\n","8/8 [==============================] - 1s 170ms/step - loss: 1.4314 - acc: 0.6719\n","8/8 [==============================] - 21s 3s/step - loss: 0.2098 - acc: 0.8988 - val_loss: 1.4314 - val_acc: 0.6719\n","Epoch 65/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3238 - acc: 0.8547Epoch 1/100\n","8/8 [==============================] - 1s 183ms/step - loss: 1.9620 - acc: 0.5977\n","8/8 [==============================] - 22s 3s/step - loss: 0.3066 - acc: 0.8676 - val_loss: 1.9620 - val_acc: 0.5977\n","Epoch 66/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1977 - acc: 0.9275Epoch 1/100\n","8/8 [==============================] - 1s 169ms/step - loss: 2.1450 - acc: 0.5977\n","8/8 [==============================] - 25s 3s/step - loss: 0.1933 - acc: 0.9287 - val_loss: 2.1450 - val_acc: 0.5977\n","Epoch 67/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2921 - acc: 0.8898Epoch 1/100\n","8/8 [==============================] - 1s 177ms/step - loss: 2.1035 - acc: 0.5898\n","8/8 [==============================] - 23s 3s/step - loss: 0.2826 - acc: 0.8921 - val_loss: 2.1035 - val_acc: 0.5898\n","Epoch 68/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2246 - acc: 0.9105Epoch 1/100\n","8/8 [==============================] - 1s 174ms/step - loss: 2.1775 - acc: 0.5898\n","8/8 [==============================] - 23s 3s/step - loss: 0.2239 - acc: 0.9088 - val_loss: 2.1775 - val_acc: 0.5898\n","Epoch 69/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1934 - acc: 0.9170Epoch 1/100\n","8/8 [==============================] - 1s 175ms/step - loss: 2.1516 - acc: 0.5938\n","8/8 [==============================] - 23s 3s/step - loss: 0.1950 - acc: 0.9210 - val_loss: 2.1516 - val_acc: 0.5938\n","Epoch 70/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1878 - acc: 0.9157Epoch 1/100\n","8/8 [==============================] - 1s 172ms/step - loss: 0.8397 - acc: 0.7422\n","8/8 [==============================] - 23s 3s/step - loss: 0.1971 - acc: 0.9132 - val_loss: 0.8397 - val_acc: 0.7422\n","Epoch 71/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2801 - acc: 0.8755Epoch 1/100\n","8/8 [==============================] - 1s 176ms/step - loss: 2.4093 - acc: 0.5781\n","8/8 [==============================] - 22s 3s/step - loss: 0.2642 - acc: 0.8888 - val_loss: 2.4093 - val_acc: 0.5781\n","Epoch 72/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2193 - acc: 0.9066Epoch 1/100\n","8/8 [==============================] - 1s 176ms/step - loss: 1.5994 - acc: 0.6562\n","8/8 [==============================] - 22s 3s/step - loss: 0.2091 - acc: 0.9132 - val_loss: 1.5994 - val_acc: 0.6562\n","Epoch 73/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1489 - acc: 0.9416Epoch 1/100\n","8/8 [==============================] - 1s 170ms/step - loss: 3.4744 - acc: 0.5234\n","8/8 [==============================] - 22s 3s/step - loss: 0.1660 - acc: 0.9310 - val_loss: 3.4744 - val_acc: 0.5234\n","Epoch 74/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2164 - acc: 0.9152Epoch 1/100\n","8/8 [==============================] - 1s 164ms/step - loss: 2.7425 - acc: 0.5742\n","8/8 [==============================] - 22s 3s/step - loss: 0.1944 - acc: 0.9155 - val_loss: 2.7425 - val_acc: 0.5742\n","Epoch 75/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2077 - acc: 0.9029Epoch 1/100\n","8/8 [==============================] - 1s 166ms/step - loss: 1.0547 - acc: 0.7188\n","8/8 [==============================] - 22s 3s/step - loss: 0.1902 - acc: 0.9032 - val_loss: 1.0547 - val_acc: 0.7188\n","Epoch 76/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1967 - acc: 0.9163Epoch 1/100\n","8/8 [==============================] - 1s 170ms/step - loss: 1.7015 - acc: 0.6758\n","8/8 [==============================] - 25s 3s/step - loss: 0.1929 - acc: 0.9160 - val_loss: 1.7015 - val_acc: 0.6758\n","Epoch 77/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2634 - acc: 0.8612Epoch 1/100\n","8/8 [==============================] - 1s 180ms/step - loss: 2.7426 - acc: 0.5703\n","8/8 [==============================] - 22s 3s/step - loss: 0.2548 - acc: 0.8710 - val_loss: 2.7426 - val_acc: 0.5703\n","Epoch 78/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.2108 - acc: 0.9222Epoch 1/100\n","8/8 [==============================] - 1s 172ms/step - loss: 2.5546 - acc: 0.5820\n","8/8 [==============================] - 22s 3s/step - loss: 0.2093 - acc: 0.9210 - val_loss: 2.5546 - val_acc: 0.5820\n","Epoch 79/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1768 - acc: 0.9209Epoch 1/100\n","8/8 [==============================] - 1s 174ms/step - loss: 2.0340 - acc: 0.6406\n","8/8 [==============================] - 22s 3s/step - loss: 0.1785 - acc: 0.9255 - val_loss: 2.0340 - val_acc: 0.6406\n","Epoch 80/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.3501 - acc: 0.8911Epoch 1/100\n","8/8 [==============================] - 1s 161ms/step - loss: 2.3619 - acc: 0.5898\n","8/8 [==============================] - 19s 2s/step - loss: 0.3144 - acc: 0.8915 - val_loss: 2.3619 - val_acc: 0.5898\n","Epoch 81/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1684 - acc: 0.9286Epoch 1/100\n","8/8 [==============================] - 1s 166ms/step - loss: 2.2035 - acc: 0.6172\n","8/8 [==============================] - 25s 3s/step - loss: 0.1671 - acc: 0.9277 - val_loss: 2.2035 - val_acc: 0.6172\n","Epoch 82/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1479 - acc: 0.9431Epoch 1/100\n","8/8 [==============================] - 1s 115ms/step - loss: 1.7958 - acc: 0.6602\n","8/8 [==============================] - 24s 3s/step - loss: 0.1431 - acc: 0.9453 - val_loss: 1.7958 - val_acc: 0.6602\n","Epoch 83/100\n","7/8 [=========================>....] - ETA: 2s - loss: 0.1480 - acc: 0.9118Epoch 1/100\n","1/8 [==>...........................] - ETA: 1s - loss: 3.1207 - acc: 0.5312"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7zNPRWOVJdOH","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lrw3rnNAnNNR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}